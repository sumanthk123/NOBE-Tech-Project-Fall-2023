{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import files necessary\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# import csv file with data \n",
    "data = pd.read_csv('your_data.csv')  # Replace 'your_data.csv' with your CSV file path\n",
    "# Assuming columns are organized where features are in columns and labels are in a separate column\n",
    "X = data.iloc[:, :-1].values  # Features\n",
    "y = data.iloc[:, -1].values   # Labels\n",
    "\n",
    "# initialize CNN \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# compile the model \n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# start CNN on train data \n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "model.save('my_model.h5')  # Save the model locally first\n",
    "\n",
    "import boto3\n",
    "s3 = boto3.client('s3', region_name='your_region')  # Replace 'your_region' with your AWS region\n",
    "\n",
    "bucket_name = 'your_bucket_name'  # Replace 'your_bucket_name' with your bucket name\n",
    "object_name = 'my_model.h5'\n",
    "\n",
    "s3.upload_file('my_model.h5', bucket_name, object_name)  # Upload the model to S3\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
